#!/usr/bin/env python3

from pathlib import Path
import pandas
import logging
import shutil


#############
# FUNCTIONS #
#############

def get_indiv_reads(wildcards):
    '''
    get a list of reads to concat
    '''
    # barcode_csv = 'output/010_demux/barcode_distance.csv'
    # my_indiv = 'indiv83_mhyp_lincoln'
    # my_dist = 1
    read_path = Path(outdir, 'tmp/reads/{bc}_r{r}.fastq')
    my_dist = int(max_dist)
    my_indiv = wildcards.indiv
    barcode_csv = checkpoints.plot_barcode_distance.get(
        **wildcards).output['report']
    found_bc = pandas.read_csv(barcode_csv)
    my_bcs = sorted(set(
        found_bc.loc[(found_bc['sample'] == my_indiv) & (found_bc.dist <= my_dist)]['found_barcode']))
    return(
        {'r1': expand(read_path, bc=my_bcs, r=['1']),
         'r2': expand(read_path, bc=my_bcs, r=['2'])})


def kept_indiv_reads(wildcards):
    '''
    Parse the barcode_csv to find which indivs we want to keep
    '''
    # barcode_csv = 'output/010_demux/barcode_distance.csv'
    barcode_csv = checkpoints.plot_barcode_distance.get(
        **wildcards).output['report']
    read_path = Path(outdir, 'reads/{indiv}_r{r}.fastq.gz')
    found_bc = pandas.read_csv(barcode_csv)
    kept_df = found_bc.loc[(found_bc.dist == 0) & (found_bc.Reads > 0)]
    kept_indivs = sorted(set(kept_df['sample']))
    return(expand(read_path, indiv=kept_indivs, r=['1', '2']))


def filter_trim_stats(wildcards):
    '''
    Parse the barcode_csv to find which indivs we want to keep
    '''
    # barcode_csv = 'output/010_demux/barcode_distance.csv'
    barcode_csv = checkpoints.plot_barcode_distance.get(
        **wildcards).output['report']
    stat_path = Path(outdir, 'stats/{indiv}.{step}.txt')
    found_bc = pandas.read_csv(barcode_csv)
    kept_df = found_bc.loc[(found_bc.dist == 0) & (found_bc.Reads > 0)]
    kept_indivs = sorted(set(kept_df['sample']))
    return(expand(stat_path, indiv=kept_indivs, step=wildcards.step))


def trim_stat_files(wildcards):
    '''
    Parse the barcode_csv to find which indivs we want to keep
    '''
    # barcode_csv = 'output/010_demux/barcode_distance.csv'
    barcode_csv = checkpoints.plot_barcode_distance.get(
        **wildcards).output['report']
    stat_path = Path(outdir, 'stats/{indiv}.trim.stats.txt')
    found_bc = pandas.read_csv(barcode_csv)
    kept_df = found_bc.loc[(found_bc.dist == 0) & (found_bc.Reads > 0)]
    kept_indivs = sorted(set(kept_df['sample']))
    return(expand(stat_path, indiv=kept_indivs))


###########
# GLOBALS #
###########

max_dist = 0

# from args
outdir = config['outdir']
mem_gb = config['mem_gb']
max_threads = config['threads']
barcode_file = config['samples_csv']
muxed_r1 = config['r1_file']
muxed_r2 = config['r2_file']

# get all indivs
barcode_csv = pandas.read_csv(barcode_file)
all_indivs = sorted(set(barcode_csv['sample']))

# containers
bbmap = 'shub://TomHarrop/seq-utils:bbmap_38.76'
bioconductor = 'shub://TomHarrop/r-containers:bioconductor_3.11'


#########
# RULES #
#########

wildcard_constraints:
    indiv = '|'.join(all_indivs),
    step = 'filter|trim'

onsuccess:
    try:
        shutil.rmtree(Path(outdir, 'tmp'))
    except FileNotFoundError as e:
        logging.info(e)

rule target:
    input:
        kept_indiv_reads,
        Path(outdir, 'barcode_content.pdf'),
        Path(outdir, 'barcode_distance.pdf'),
        Path(outdir, 'adaptor_content.pdf'),
        Path(outdir, 'stats/filter.all.txt'),

rule plot_adaptor_content:
    input:
        summary_file = Path(outdir, 'stats/trim.all.txt'),
        trim_files = trim_stat_files
    output:
        plot = Path(outdir, 'adaptor_content.pdf')
    log:
        Path(outdir, 'logs/plot_adaptor_content.log')
    singularity:
        bioconductor
    script:
        shutil.which('plot_adaptor_content.R')

rule combine_step_logs:
    input:
        step_files = filter_trim_stats
    output:
        step_data = Path(outdir, 'stats/{step}.all.txt')
    log:
        Path(outdir, 'logs/combine_step_logs.{step}.log')
    singularity:
        bioconductor
    script:
        shutil.which('combine_step_logs.R')

rule grep_logs:
    input:
        Path(outdir, 'stats/{indiv}.{step}.log.txt')
    output:
        temp(Path(outdir, 'stats/{indiv}.{step}.txt'))
    shell:
        'grep \"^Input:\" {input} '
        '| tr -s \' \' '
        '| cut -f1,2,4 '
        '> {output} '
        '; '
        'grep \"^Result:\" {input} '
        '| tr -s \' \' '
        '| cut -f1,2,3 '
        '>> {output}'

rule trim:
    input:
        fq = Path(outdir, 'tmp/{indiv}_filter.fastq'),
    output:
        r1 = Path(outdir, 'reads/{indiv}_r1.fastq.gz'),
        r2 = Path(outdir, 'reads/{indiv}_r2.fastq.gz'),
        stats = Path(outdir, 'stats/{indiv}.trim.stats.txt'),
        log = Path(outdir, 'stats/{indiv}.trim.log.txt')
    log:
        Path(outdir, 'logs/{indiv}.trim.log')
    params:
        trim = '/adapters.fa'
    threads:
        max(4, workflow.cores // len(all_indivs))
    singularity:
        bbmap
    shell:
        'bbduk.sh '
        'threads={threads} '
        'in={input.fq} '
        'int=t '
        'out={output.r1} '
        'out2={output.r2} '
        'zl=9 '
        'ref={params.trim} '
        'ktrim=r k=23 mink=11 hdist=1 tpe tbo '
        'forcetrimmod=5 '
        'stats={output.stats} '
        '2> >( tee -a {output.log} &> {log} )'

rule filter:
    input:
        r1 = Path(outdir, 'tmp/indiv_reads/{indiv}_r1.fastq'),
        r2 = Path(outdir, 'tmp/indiv_reads/{indiv}_r2.fastq')
    output:
        pipe = pipe(Path(outdir, 'tmp/{indiv}_filter.fastq')),
        stats = Path(outdir, 'stats/{indiv}.filter.stats.txt'),
        log = Path(outdir, 'stats/{indiv}.filter.log.txt')
    params:
        filter = '/phix174_ill.ref.fa.gz'
    log:
        Path(outdir, 'logs/{indiv}.filter.log')
    threads:
        max(4, workflow.cores // len(all_indivs))
    singularity:
        bbmap
    shell:
        'bbduk.sh '
        'threads={threads} '
        'in={input.r1} '
        'in2={input.r2} '
        'int=f '
        'out=stdout.fastq '
        'ref={params.filter} '
        'hdist=1 '
        'stats={output.stats} '
        '>>{output.pipe} '
        '2> >( tee -a {output.log} &> {log} )'


rule mv_reads:
    input:
        unpack(get_indiv_reads),
    output:
        r1 = temp(Path(outdir, 'tmp/indiv_reads/{indiv}_r1.fastq')),
        r2 = temp(Path(outdir, 'tmp/indiv_reads/{indiv}_r2.fastq'))
    shell:
        'cat {input.r1} > {output.r1} & '
        'cat {input.r2} > {output.r2} & '
        'wait'


checkpoint plot_barcode_distance:
    input:
        stats = Path(outdir, 'demux_stats.txt'),
        barcodes = barcode_file,
        foundbc = Path(outdir, 'stats/hamming_distances.Rds')
    output:
        plot = Path(outdir, 'barcode_distance.pdf'),
        report = Path(outdir, 'stats/barcode_distance.csv')
    params:
        read_min_freq = 1e-4,
        max_mismatches = 2
    log:
        Path(outdir, 'logs/plot_barcode_distance.log')
    singularity:
        bioconductor
    script:
        shutil.which('plot_barcode_distance.R')

rule calculate_hamming_distance:
    input:
        stats = Path(outdir, 'demux_stats.txt'),
        barcodes = barcode_file
    output:
        foundbc = Path(outdir, 'stats/hamming_distances.Rds')
    log:
        Path(outdir, 'logs/calculate_hamming_distance.log')
    threads:
        workflow.cores
    singularity:
        bioconductor
    script:
        shutil.which('calculate_hamming_distance.R')

rule plot_barcode_content:
    input:
        stats = Path(outdir, 'demux_stats.txt'),
    output:
        plot = Path(outdir, 'barcode_content.pdf'),
    log:
        Path(outdir, 'logs/plot_barcode_content.log')
    singularity:
        bioconductor
    script:
        shutil.which('plot_barcode_content.R')

checkpoint demultiplex:
    input:
        # r1 = 'data/muxed/Undetermined_S0_L002_R1_001.fastq.gz',
        # r2 = 'data/muxed/Undetermined_S0_L002_R2_001.fastq.gz'
        r1 = muxed_r1,
        r2 = muxed_r2
    output:
        directory(Path(outdir, 'tmp/reads')),
        stats = Path(outdir, 'demux_stats.txt')
    log:
        Path(outdir, 'logs/demultiplex.log')
    params:
        out = Path(outdir, 'tmp/reads/%_r1.fastq').as_posix(),
        out2 = Path(outdir, 'tmp/reads/%_r2.fastq').as_posix(),
        streams = min(workflow.cores, 40) // 2,
        mem_gb = mem_gb
    threads:
        min(workflow.cores, 40)
    singularity:
        bbmap
    shell:
        'demuxbyname.sh '
        'in={input.r1} '
        'in2={input.r2} '
        'out={params.out} '
        'out2={params.out2} '
        'stats={output.stats} '
        'streams={params.streams} '
        'delimiter=: '
        'column=10 '
        'prefixmode=f '
        '-Xmx{mem_gb}g '
        '2> {log}'
